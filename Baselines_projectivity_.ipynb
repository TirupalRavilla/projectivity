{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baselines_projectivity.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O3rJMJZ2kdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import linear_model, preprocessing\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re \n",
        "# nltk.download('stopwords')\n",
        "# nltk.download()\n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4aV5BIb2klE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('all')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J53cszcY3T4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentences(X):\n",
        "  documents = []\n",
        "  stemmer = WordNetLemmatizer()\n",
        "  for sen in range(0, len(X)):\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    document = re.sub(r'^\"', '', document)\n",
        "    document = re.sub(r'\"$', '', document)\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    document = document.lower()\n",
        "    #     document = document.split()\n",
        "    #     document = [stemmer.lemmatize(word) for word in document]\n",
        "    #     document = ' '.join(document)\n",
        "    documents.append(document)\n",
        "  print(len(documents))\n",
        "  return documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kabZypm1eUSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.help.upenn_tagset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfMOnifwEa6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test(test):\n",
        "  df= pd.read_csv(test,delimiter='\\t',encoding='utf-8')\n",
        "  ts_st=np.array(df['sentence'].values)\n",
        "  ts_ft=np.array(df['Future'].values)\n",
        "  ts_pt=np.array(df['Past'].values)\n",
        "  return ts_st,ts_ft,ts_pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsQgE6-fM91U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_train_val(train,val):\n",
        "  df= pd.read_csv(train,delimiter='\\t',encoding='utf-8')\n",
        "  tr_st=np.array(df['sentence'].values)\n",
        "  tr_ft=np.array(df['Future'].values)\n",
        "  tr_pt=np.array(df['Past'].values)\n",
        "  df= pd.read_csv(val,delimiter='\\t',encoding='utf-8')\n",
        "  val_st=np.array(df['sentence'].values)\n",
        "  val_ft=np.array(df['Future'].values)\n",
        "  val_pt=np.array(df['Past'].values)\n",
        "  return tr_st,tr_ft,tr_pt, val_st,val_ft,val_pt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjFS3_KH3Xee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_past(document):\n",
        "  past=False\n",
        "  tokens=nltk.word_tokenize(document)\n",
        "  word_pos=nltk.pos_tag(tokens)\n",
        "  pos=[pos for (word,pos) in word_pos]\n",
        "#   print(pos)\n",
        "  if ('VBD' in pos) or ('VBN' in pos):\n",
        "    past=True\n",
        "  return past"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUbq-GrRVwV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0f33d766-881c-478b-ce9d-3dcd2e23a169"
      },
      "source": [
        "detect_future('I am going to present it, tomorrow')"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'going', 'to', 'present', 'it', ',', 'tomorrow']\n",
            "['PRP', 'VBP', 'VBG', 'TO', 'VB', 'PRP', ',', 'NN']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHsVy6fq4CBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect_future(document):\n",
        "  future=False\n",
        "  tokens=nltk.word_tokenize(document)\n",
        "  word_pos=nltk.pos_tag(tokens)\n",
        "  pos=[pos for (word,pos) in word_pos]\n",
        "  words=[word for (word,pos) in word_pos]\n",
        "#   print(words)\n",
        "#   print(pos)\n",
        "  for i in range(len(pos)):\n",
        "    if(i+1<len(pos)):\n",
        "      #modal verb\n",
        "      if((pos[i] == 'MD') and (words[i] in ['shall','will','\\'ll']) and ('VB' in pos[i+1:])):\n",
        "        future=True\n",
        "    if(i+3<len(pos)):\n",
        "      #going-to future \n",
        "      if((pos[i]=='VBP') and (pos[i+1]=='VBG') and (pos[i+2]=='TO') and ('VB' in pos[i+2:])):\n",
        "        future=True\n",
        "      if(i>0):\n",
        "        if((('VBP' in pos[:i]) or 'VBZ' in pos[:i]) and (words[i+1]=='going') and (pos[i+2]=='TO') and ('VB' in pos[i+2:])):\n",
        "          future=True\n",
        "  return future"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fVj150LD-q0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "409b0964-87ee-4c28-c690-974b13f86227"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YdAa7MqAT1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datapath = 'gdrive/My Drive/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFCYGgsmM7rT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a713bbe0-eca5-431b-9b95-303a7e19da19"
      },
      "source": [
        "trainfile=datapath+'train.txt'\n",
        "valfile=datapath+'validation.txt'\n",
        "tr_st,tr_ft,tr_pt, val_st,val_ft,val_pt=load_train_val(trainfile,valfile)\n",
        "testfile=datapath+'test.txt'\n",
        "ts_st,ts_ft,ts_pt=load_test(testfile)\n",
        "\n",
        "tr_st = preprocess_sentences(tr_st)\n",
        "val_st = preprocess_sentences(val_st)\n",
        "ts_st = preprocess_sentences(ts_st)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1776\n",
            "592\n",
            "593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMZECWYHQg7f",
        "colab_type": "text"
      },
      "source": [
        "**Rule Based Baseline:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUIbxVuEEHyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cae1faa3-61fc-43c4-85a7-8778b983c444"
      },
      "source": [
        "pt_pred=[(1 if detect_past(sent) else 0) for sent in ts_st]\n",
        "acc = np.mean(pt_pred == ts_pt)\n",
        "print('Test Past Accuaracy = {0:f}'.format(acc))\n",
        "ft_pred=[(1 if detect_future(sent) else 0) for sent in ts_st]\n",
        "acc = np.mean(ft_pred == ts_ft)\n",
        "print('Test Future Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Past Accuaracy = 0.691400\n",
            "Test Future Accuaracy = 0.634064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT4KX5N2Enh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4995387f-af97-4753-e030-45949a8a68d6"
      },
      "source": [
        "pt_pred=[(1 if detect_past(sent) else 0) for sent in tr_st]\n",
        "acc = np.mean(pt_pred == tr_pt)\n",
        "print('Train Past Accuaracy = {0:f}'.format(acc))\n",
        "ft_pred=[(1 if detect_future(sent) else 0) for sent in tr_st]\n",
        "acc = np.mean(ft_pred == tr_ft)\n",
        "print('Train Future Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Past Accuaracy = 0.724099\n",
            "Train Future Accuaracy = 0.554617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBjoQat8E2BK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ed316dbc-8959-4ca3-b1f7-a09fbf728622"
      },
      "source": [
        "pt_pred=[(1 if detect_past(sent) else 0) for sent in val_st]\n",
        "acc = np.mean(pt_pred == val_pt)\n",
        "print('Val Past Accuaracy = {0:f}'.format(acc))\n",
        "ft_pred=[(1 if detect_future(sent) else 0) for sent in val_st]\n",
        "acc = np.mean(ft_pred == val_ft)\n",
        "print('Val Future Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Val Past Accuaracy = 0.736486\n",
            "Val Future Accuaracy = 0.548986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMAYjNTgQ9Ak",
        "colab_type": "text"
      },
      "source": [
        "**Rule Based Baseline on all the labeled data:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMTyhlBMIQ4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cf148b2c-c815-4d70-99ae-35b672bcde15"
      },
      "source": [
        "pt_pred=[(1 if detect_past(sent) else 0) for sent in np.concatenate([tr_st,val_st,ts_st])]\n",
        "acc = np.mean(pt_pred == np.concatenate([tr_pt,val_pt,ts_pt]))\n",
        "print('Total Past Accuaracy = {0:f}'.format(acc))\n",
        "ft_pred=[(1 if detect_future(sent) else 0) for sent in np.concatenate([tr_st,val_st,ts_st])]\n",
        "acc = np.mean(ft_pred == np.concatenate([tr_ft,val_ft,ts_ft]))\n",
        "print('Total Future Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Past Accuaracy = 0.720027\n",
            "Total Future Accuaracy = 0.569402\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wx4fFJbAQn-N",
        "colab_type": "text"
      },
      "source": [
        "**Most Frequent Class Baseline:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyi1BvbQ4tUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lrd8897Olvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def majority_acc(labels,test):\n",
        "  unique_vals = Counter(labels).keys()\n",
        "  unique_counts = Counter(labels).values()\n",
        "  maj=np.fromiter(unique_vals,dtype=int)[np.argmax(np.fromiter(unique_counts,dtype=int))]\n",
        "  labels_maj=np.full((len(test),),maj)\n",
        "  acc = np.mean(labels_maj == test)\n",
        "  return acc\n",
        "#   print('Past Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXH9hBlUBw3A",
        "colab_type": "text"
      },
      "source": [
        "**Most Frequent class Baseline:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvn0OY1bAyNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "1dc1b71f-6474-4919-a41d-780c6b67e997"
      },
      "source": [
        "\n",
        "acc= majority_acc(np.concatenate([tr_pt,val_pt]),ts_pt)\n",
        "print('Past Test maj Accuaracy = {0:f}'.format(acc))\n",
        "\n",
        "acc= majority_acc(np.concatenate([tr_ft,val_ft]),ts_ft)\n",
        "print('Future Test maj Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Past Test maj Accuaracy = 0.546374\n",
            "Future Test maj Accuaracy = 0.505902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyzF-m3B5hc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faACa2IRIRDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0e2e0b26-391f-4e7f-f4aa-a7c4e3b7dd5f"
      },
      "source": [
        "acc= majority_acc(tr_pt)\n",
        "print('Past Train maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(ts_pt)\n",
        "print('Past Test maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(val_pt)\n",
        "print('Past Validation maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(tr_ft)\n",
        "print('Future Train maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(ts_ft)\n",
        "print('Future Test maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(val_ft)\n",
        "print('Future tr maj Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Past Train maj Accuaracy = 0.619369\n",
            "Past Test maj Accuaracy = 0.546374\n",
            "Past Validation maj Accuaracy = 0.594595\n",
            "Future Train maj Accuaracy = 0.574324\n",
            "Future Test maj Accuaracy = 0.505902\n",
            "Future tr maj Accuaracy = 0.567568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek0GbPRoRRfR",
        "colab_type": "text"
      },
      "source": [
        "**Majority Baseline on all the labeled data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46ayvRTMRK8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d6308e60-cbe0-4599-fcc9-c6f7f22025b3"
      },
      "source": [
        "acc= majority_acc(np.concatenate([tr_pt,val_pt,ts_pt]))\n",
        "print('Past Total maj Accuaracy = {0:f}'.format(acc))\n",
        "acc= majority_acc(np.concatenate([tr_ft,val_ft,ts_ft]))\n",
        "print('Future Total maj Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Past Total maj Accuaracy = 0.599797\n",
            "Future Total maj Accuaracy = 0.559271\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeMLMbMvB8tS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWs5-G1b62gv",
        "colab_type": "text"
      },
      "source": [
        "**sklearn DummyClassifier baselines:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXjwu_ua4uy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "0697c518-0a0e-4605-b9be-062cbe1ec146"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "print('Past: ')\n",
        "for strategy in ['stratified', 'most_frequent', 'prior', 'uniform']:\n",
        "    dummy = DummyClassifier(strategy=strategy)\n",
        "    dummy.fit(np.concatenate([tr_st,val_st]), np.concatenate([tr_pt,val_pt]))\n",
        "    print(strategy,': ',dummy.score(ts_st, ts_pt))\n",
        "print('Future: ')\n",
        "for strategy in ['stratified', 'most_frequent', 'prior', 'uniform']:\n",
        "    dummy = DummyClassifier(strategy=strategy)\n",
        "    dummy.fit(np.concatenate([tr_st,val_st]), np.concatenate([tr_ft,val_ft]))\n",
        "    print(strategy,': ',dummy.score(ts_st, ts_ft))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Past: \n",
            "stratified :  0.5075885328836425\n",
            "most_frequent :  0.5463743676222597\n",
            "prior :  0.5463743676222597\n",
            "uniform :  0.4991568296795953\n",
            "Future: \n",
            "stratified :  0.5008431703204047\n",
            "most_frequent :  0.5059021922428331\n",
            "prior :  0.5059021922428331\n",
            "uniform :  0.49409780775716694\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}