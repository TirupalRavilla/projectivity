{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projectivity LSTM Glove .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9GM_TH5roB0",
        "colab_type": "text"
      },
      "source": [
        "Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu6pel2nWGBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re \n",
        "# nltk.download('stopwords')\n",
        "# nltk.download()\n",
        "from nltk.corpus import stopwords "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DUffYSxtJl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.download('punkt')\n",
        "# nltk.download('all')\n",
        "# nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGyIVHTtrv2F",
        "colab_type": "text"
      },
      "source": [
        "No longer necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBGoLlU_WIi4",
        "colab_type": "code",
        "outputId": "778c0337-0f30-446e-ddfc-0444009e32a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# data_path='./'\n",
        "# os.chdir(data_path)\n",
        "files=glob.glob('*.txt')\n",
        "\n",
        "sents=[]\n",
        "tagsP=[]\n",
        "tagsF=[]\n",
        "emptyin=[]\n",
        "for f in files:\n",
        "    file = open(f)\n",
        "    df= pd.read_csv(file,delimiter='\\t',encoding='utf-8')\n",
        "    emptyin=df[df['Past'].isnull()].index.tolist()\n",
        "    st=np.delete(np.array(df['sentence'].values),emptyin)\n",
        "    ft=np.delete(np.array(df['Future'].values),emptyin)\n",
        "    pt=np.delete(np.array(df['Past'].values),emptyin)\n",
        "    sents.extend(list(st))\n",
        "    tagsF.extend(list(ft))\n",
        "    tagsP.extend(list(pt))\n",
        "    print(emptyin)\n",
        "X=np.asarray(sents)\n",
        "yf=np.asarray(tagsF)\n",
        "yp=np.asarray(tagsP)\n",
        "print(len(X))\n",
        "print(len(yf))\n",
        "print(len(yp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[103, 266, 280, 301, 314, 392, 412, 474, 664, 685, 688, 778, 875, 926, 975]\n",
            "[49, 82, 195, 258, 533, 541, 577, 648, 726, 942]\n",
            "[51, 90, 214, 273, 304, 404, 458, 511, 527, 640, 664, 769, 911, 995]\n",
            "2961\n",
            "2961\n",
            "2961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9eszsIAr6iN",
        "colab_type": "text"
      },
      "source": [
        "No longer necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMJZxPyQ6iF",
        "colab_type": "code",
        "outputId": "1d1f74a3-d0dd-490f-c0ff-aa1123730911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f='projectivity.txt'\n",
        "file=open(f)\n",
        "df= pd.read_csv(file,delimiter='\\t',encoding='utf-8')\n",
        "emptyin=df[df['Past'].isnull()].index\n",
        "dt=df.loc[:, 'id':'Future']\n",
        "dt=dt.drop(emptyin)\n",
        "print(len(dt))\n",
        "# dt=np.delete(np.array(df.loc[:, 'A':'E'].values),emptyin)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVKWLfQrr89H",
        "colab_type": "text"
      },
      "source": [
        "No longer necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8l5b-sHCCF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data_and_store(df):\n",
        "  train, validation, test = np.split(df, [int(.6*len(df)), int(.8*len(df))])\n",
        "  train.to_csv('train', sep='\\t')\n",
        "  validation.to_csv('validation', sep='\\t')\n",
        "  test.to_csv('test', sep='\\t')\n",
        "  print('Done!')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Utar4lc9alxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_data_and_store(dt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxZrfr29nAm3",
        "colab_type": "text"
      },
      "source": [
        "Compile and run from here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIVbzDgMnIHH",
        "colab_type": "text"
      },
      "source": [
        "To load the train and validation data from TSV files.\n",
        "\n",
        "Arguments: train file, validation file\n",
        "\n",
        "Returns:\n",
        "\n",
        "tr_st: Training sentences\n",
        "tr_ft: Training Future Labels\n",
        "tr_pt: Trainiing past labels\n",
        "val_st: Validation sentences\n",
        "val_ft: Validation Future Labels\n",
        "val_pt: Validation past labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhIpVrntXle-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_train_val(train,val):\n",
        "  df= pd.read_csv(train,delimiter='\\t',encoding='utf-8')\n",
        "  tr_st=np.array(df['sentence'].values)\n",
        "  tr_ft=np.array(df['Future'].values)\n",
        "  tr_pt=np.array(df['Past'].values)\n",
        "  df= pd.read_csv(val,delimiter='\\t',encoding='utf-8')\n",
        "  val_st=np.array(df['sentence'].values)\n",
        "  val_ft=np.array(df['Future'].values)\n",
        "  val_pt=np.array(df['Past'].values)\n",
        "  return tr_st,tr_ft,tr_pt, val_st,val_ft,val_pt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZFGdfLUm_-d",
        "colab_type": "text"
      },
      "source": [
        "Method to load the test data from TSV file.\n",
        "\n",
        "Arguments: test file\n",
        "\n",
        "Returns:\n",
        "\n",
        "ts_st: Test sentences\n",
        "ts_ft: Test Future Labels\n",
        "ts_pt: Test past labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxxZx8cfjN4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_test(test):\n",
        "  df= pd.read_csv(test,delimiter='\\t',encoding='utf-8')\n",
        "  ts_st=np.array(df['sentence'].values)\n",
        "  ts_ft=np.array(df['Future'].values)\n",
        "  ts_pt=np.array(df['Past'].values)\n",
        "  return ts_st,ts_ft,ts_pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Z8FXCuHoRNM",
        "colab_type": "text"
      },
      "source": [
        "To preprocess sentences:\n",
        "Removing some special characters, spaces and tabs, and conversion to lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olOQd2m9VDBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_sentences(X):\n",
        "  documents = []\n",
        "  stemmer = WordNetLemmatizer()\n",
        "  for sen in range(0, len(X)):\n",
        "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
        "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
        "    document = re.sub(r'^\"', '', document)\n",
        "    document = re.sub(r'\"$', '', document)\n",
        "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
        "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
        "    document = re.sub(r'^b\\s+', '', document)\n",
        "    document = document.lower()\n",
        "    #     document = document.split()\n",
        "    #     document = [stemmer.lemmatize(word) for word in document]\n",
        "    #     document = ' '.join(document)\n",
        "    documents.append(document)\n",
        "  print(len(documents))\n",
        "  return documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUjEdlLqoju2",
        "colab_type": "text"
      },
      "source": [
        "Converts sentences to lists of features\n",
        "\n",
        "Uncomment code as needed for features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQlVvKEebN01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent_to_features(documents):\n",
        "  feature_docs=[]\n",
        "  for document in documents:\n",
        "    tokens=nltk.word_tokenize(document)\n",
        "    bigrams = list(nltk.bigrams(tokens))\n",
        "    #pos_bigrams = list(nltk.bigrams([pos for (word,pos) in nltk.pos_tag(tokens)]))\n",
        "    document=[word for (word,pos) in nltk.pos_tag(tokens)]#+' '+pos\n",
        "#     document.extend([w1+'_'+w2 for (w1,w2) in bigrams])\n",
        "    #     document.extend([w1+'_'+w2 for (w1,w2) in pos_bigrams])\n",
        "    #     document.extend([pos for (word,pos) in nltk.pos_tag(tokens)])\n",
        "    #     document = document.split()\n",
        "    #     document = [stemmer.lemmatize(word) for word in document]\n",
        "    document = ' '.join(document)\n",
        "    feature_docs.append(document)\n",
        "  return feature_docs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iQzX5Oyo6hl",
        "colab_type": "text"
      },
      "source": [
        "This is not necesasry unless the code is being run on a Colab notebook, and the data is stored on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYP9853kPwtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cf472ead-0be2-498f-d44c-7fdf8e07e48b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmgo2XqVpNL1",
        "colab_type": "text"
      },
      "source": [
        "Path to the location where the data resides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKhqgC5FQHyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datapath = 'gdrive/My Drive/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "westpD8MpWDa",
        "colab_type": "text"
      },
      "source": [
        "Loading the train and validation data\n",
        "\n",
        "Preprocessing the data\n",
        "\n",
        "Feature extraction if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VjfiO4FeJz6",
        "colab_type": "code",
        "outputId": "d74af404-d8d5-4590-a6fb-6af0cf792bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "#loading train and validation data\n",
        "trainfile=datapath+'train.txt'\n",
        "valfile=datapath+'validation.txt'\n",
        "tr_st,tr_ft,tr_pt, val_st,val_ft,val_pt=load_train_val(trainfile,valfile)\n",
        "\n",
        "#preprocessing\n",
        "tr_st = preprocess_sentences(tr_st)\n",
        "val_st = preprocess_sentences(val_st)\n",
        "\n",
        "#feature extraction\n",
        "# tr_st = sent_to_features(tr_st)\n",
        "# val_st = sent_to_features(val_st)\n",
        "\n",
        "print('Train size: ',len(tr_st))\n",
        "print('Val size: ',len(val_st))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1776\n",
            "592\n",
            "Train size:  1776\n",
            "Val size:  592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUwpVDvpCT7n",
        "colab_type": "code",
        "outputId": "8a51357c-751a-4c6e-8f1e-1a23f3dfc27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tr_st[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "friends and adversaries abroad were asking whether america had lost its nerve \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhyHmoYhpl5V",
        "colab_type": "text"
      },
      "source": [
        "Imports necessary for LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VngaIqK5HAoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, CuDNNLSTM, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import optimizers\n",
        "\n",
        "# from tensorflow.keras.backend import set_session\n",
        "import keras.backend as K\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2DL356Ypscx",
        "colab_type": "text"
      },
      "source": [
        "Creating a Keras Tokenizer and fitting it on train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LFo1Iwafnvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(np.concatenate((tr_st,val_st)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrBOaXLzqAsA",
        "colab_type": "text"
      },
      "source": [
        "Initializing vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flu9dPuMfuuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_index)+1\n",
        "# print(tokenizer.word_counts)\n",
        "# print(tokenizer.document_count)\n",
        "# print(tokenizer.word_index)\n",
        "# print(tokenizer.word_docs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dh-cLMCvihEX",
        "colab_type": "code",
        "outputId": "93f9251e-7e69-47e1-b286-b377d9ab0dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(vocabulary_size)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6745\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_H4rwCgqT9Y",
        "colab_type": "text"
      },
      "source": [
        "Extracting sequences from train and validation data, and padding them to a maximum length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrQ-RHoOG7Jf",
        "colab_type": "code",
        "outputId": "bb25850d-5844-400f-89cb-a0aa6ffb591b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "# vocabulary_size = 7000\n",
        "# tokenizer.fit_on_texts(np.concatenate((tr_st,val_st)))\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(tr_st)\n",
        "tr_data = pad_sequences(sequences, maxlen=145)\n",
        "sequences = tokenizer.texts_to_sequences(val_st)\n",
        "val_data = pad_sequences(sequences, maxlen=145)\n",
        "\n",
        "print(len(tr_data))\n",
        "print(len(val_data))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1776\n",
            "592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaPP6ZFFqf05",
        "colab_type": "text"
      },
      "source": [
        "Loading Glove embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGKoxGURzgxb",
        "colab_type": "code",
        "outputId": "e026bf69-0563-4ef7-d90a-c72ab315f1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(datapath+'glove.6B.300d.txt')\n",
        "embedding_values = {}\n",
        "for line in tqdm(f):\n",
        "  value = line.split(' ')\n",
        "  word = value[0]\n",
        "  coef = np.array(value[1:],dtype = 'float32')\n",
        "  embedding_values[word]=coef"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:26, 15040.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNBfnm5eqmLe",
        "colab_type": "text"
      },
      "source": [
        "Creating an embedding matrix for words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu234t4CzsfJ",
        "colab_type": "code",
        "outputId": "75adedb9-27c1-4a6c-da66-5176131d8766",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = np.zeros((vocabulary_size,300))\n",
        "for word,i in tqdm(tokenizer.word_index.items()):\n",
        "  values = embedding_values.get(word)\n",
        "  if values is not None:\n",
        "    embedding_matrix[i] = values"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 6744/6744 [00:00<00:00, 301056.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0Y21Y9aq5ig",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8vIKkokx2Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bBpZbINq9If",
        "colab_type": "text"
      },
      "source": [
        "BiLSTM for Future task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoL3XrfjKYfY",
        "colab_type": "code",
        "outputId": "4df7ab90-4722-472b-c8c6-ead0bc17c1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "#Future\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size,300, input_length = 145,weights = [embedding_matrix],trainable = False))\n",
        "# model.add(Embedding(vocabulary_size, 145, input_length=145))\n",
        "model.add(Bidirectional(LSTM(145, dropout=0.2, recurrent_dropout=0.2)))\n",
        "\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "adg= optimizers.Adagrad(lr=0.01)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adg, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "#model.fit(tr_data, tr_ft, validation_data=(val_data,val_ft), epochs=10,batch_size=128) \n",
        "model.fit(np.concatenate((tr_data,val_data)), np.concatenate((tr_ft,val_ft)), epochs=10,batch_size=64)#  validation_data=(val_data,val_ft),"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 145, 300)          2023500   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 290)               517360    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                18624     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,559,549\n",
            "Trainable params: 536,049\n",
            "Non-trainable params: 2,023,500\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "2368/2368 [==============================] - 20s 9ms/step - loss: 0.6417 - acc: 0.6334\n",
            "Epoch 2/10\n",
            "2368/2368 [==============================] - 19s 8ms/step - loss: 0.4956 - acc: 0.7720\n",
            "Epoch 3/10\n",
            "2368/2368 [==============================] - 21s 9ms/step - loss: 0.4543 - acc: 0.7935\n",
            "Epoch 4/10\n",
            "2368/2368 [==============================] - 19s 8ms/step - loss: 0.4183 - acc: 0.8184\n",
            "Epoch 5/10\n",
            "2368/2368 [==============================] - 19s 8ms/step - loss: 0.3955 - acc: 0.8222\n",
            "Epoch 6/10\n",
            "2368/2368 [==============================] - 20s 8ms/step - loss: 0.3775 - acc: 0.8412\n",
            "Epoch 7/10\n",
            "2368/2368 [==============================] - 20s 9ms/step - loss: 0.3526 - acc: 0.8484\n",
            "Epoch 8/10\n",
            "2368/2368 [==============================] - 21s 9ms/step - loss: 0.3296 - acc: 0.8623\n",
            "Epoch 9/10\n",
            "2368/2368 [==============================] - 19s 8ms/step - loss: 0.3132 - acc: 0.8682\n",
            "Epoch 10/10\n",
            "2368/2368 [==============================] - 19s 8ms/step - loss: 0.2982 - acc: 0.8771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac820b2fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoDUaHXHrD8K",
        "colab_type": "text"
      },
      "source": [
        "Stacked BiLSTM for Future task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIAM23tnQ2_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "373bc843-25a1-43e4-9f3b-d99ea6a61c27"
      },
      "source": [
        "#Future LSTM2\n",
        "K.clear_session()\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocabulary_size,300, input_length = 145,weights = [embedding_matrix],trainable = False))\n",
        "# model.add(Embedding(vocabulary_size, 145, input_length=145))\n",
        "model2.add(Bidirectional(LSTM(145, dropout=0.2, recurrent_dropout=0.2,return_sequences=True)))\n",
        "model2.add(Bidirectional(LSTM(145, dropout=0.1, recurrent_dropout=0.1)))\n",
        "model2.add(Dense(64,activation = 'relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "adg= optimizers.Adagrad(lr=0.01)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=adg, metrics=['accuracy'])\n",
        "# model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 145, 300)          2023500   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 145, 290)          517360    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 290)               505760    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                18624     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,065,309\n",
            "Trainable params: 1,041,809\n",
            "Non-trainable params: 2,023,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJT0QXx3SI1C",
        "colab_type": "code",
        "outputId": "1011d720-d3e5-4bcd-9ec8-0327e03895a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model2.fit(tr_data, tr_ft, validation_data=(val_data,val_ft), epochs=10,batch_size=128)  #epoch 15 batch 128 no relu hidden   epoch 7 batch 128 w/ relu hidden"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1776 samples, validate on 592 samples\n",
            "Epoch 1/10\n",
            "1776/1776 [==============================] - 21s 12ms/step - loss: 0.7531 - acc: 0.5225 - val_loss: 0.6418 - val_acc: 0.6166\n",
            "Epoch 2/10\n",
            "1776/1776 [==============================] - 17s 9ms/step - loss: 0.6166 - acc: 0.6830 - val_loss: 0.5272 - val_acc: 0.7652\n",
            "Epoch 3/10\n",
            "1776/1776 [==============================] - 17s 9ms/step - loss: 0.5449 - acc: 0.7534 - val_loss: 0.5056 - val_acc: 0.7652\n",
            "Epoch 4/10\n",
            "1776/1776 [==============================] - 17s 9ms/step - loss: 0.4792 - acc: 0.7889 - val_loss: 0.4991 - val_acc: 0.7838\n",
            "Epoch 5/10\n",
            "1776/1776 [==============================] - 17s 10ms/step - loss: 0.4662 - acc: 0.7990 - val_loss: 0.4925 - val_acc: 0.7686\n",
            "Epoch 6/10\n",
            "1776/1776 [==============================] - 18s 10ms/step - loss: 0.4202 - acc: 0.8232 - val_loss: 0.4277 - val_acc: 0.8176\n",
            "Epoch 7/10\n",
            "1776/1776 [==============================] - 17s 9ms/step - loss: 0.4147 - acc: 0.8153 - val_loss: 0.4505 - val_acc: 0.8041\n",
            "Epoch 8/10\n",
            "1776/1776 [==============================] - 17s 10ms/step - loss: 0.4110 - acc: 0.8300 - val_loss: 0.4221 - val_acc: 0.8176\n",
            "Epoch 9/10\n",
            "1776/1776 [==============================] - 17s 10ms/step - loss: 0.3645 - acc: 0.8480 - val_loss: 0.4571 - val_acc: 0.8176\n",
            "Epoch 10/10\n",
            "1776/1776 [==============================] - 17s 10ms/step - loss: 0.3469 - acc: 0.8575 - val_loss: 0.4445 - val_acc: 0.8007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fac753bea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR8wePLRrNg7",
        "colab_type": "text"
      },
      "source": [
        "Training on whole training data after parameter tuning, in order to use the model to evaluate the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-IS4iu57ltx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.fit(np.concatenate((tr_data,val_data)), np.concatenate((tr_ft,val_ft)), epochs=10,batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZWGyo6Gt_Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI9HnP6YriTJ",
        "colab_type": "text"
      },
      "source": [
        "Loading the Test data\n",
        "\n",
        "preprocessing the data\n",
        "\n",
        "Extracting sequences\n",
        "\n",
        "Padding the sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om3T_CwSMj_R",
        "colab_type": "code",
        "outputId": "864f8304-f2a3-4919-a7bb-8702efca55a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "testfile=datapath+'test.txt'\n",
        "ts_st,ts_ft,ts_pt=load_test(testfile)\n",
        "\n",
        "#preprocessing\n",
        "ts_st = preprocess_sentences(ts_st)\n",
        "\n",
        "#feature extraction\n",
        "#ts_st = sent_to_features(ts_st)\n",
        "sequences = tokenizer.texts_to_sequences(ts_st)\n",
        "ts_data = pad_sequences(sequences, maxlen=145)\n",
        "print(ts_data.shape)\n",
        "print(ts_ft.shape)\n",
        "# test_loss, test_acc = model.evaluate(np.append((ts_data,ts_ft),1))\n",
        "# print('Test Loss: {}'.format(test_loss))\n",
        "# print('Test Accuracy: {}'.format(test_acc))\n",
        "\n",
        "\n",
        "# print('Accuaracy = {0:f}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "593\n",
            "(593, 145)\n",
            "(593,)\n",
            "Accuracy: 83.14%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFXas8tJscK5",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the test data for future task "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvgVJ-NcsbRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "scores = model.evaluate(ts_data, ts_ft, verbose=0)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW3UEFHSsjeE",
        "colab_type": "text"
      },
      "source": [
        "Generating a classification report for the test data for future task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnKBdfMv6ezo",
        "colab_type": "code",
        "outputId": "be93daea-1468-4317-9e4c-20165c82d30a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(ts_data, batch_size=64, verbose=1)\n",
        "y_pred =(y_pred>0.5)\n",
        "\n",
        "print(classification_report(ts_ft, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "593/593 [==============================] - 2s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.77      0.82       293\n",
            "         1.0       0.80      0.89      0.84       300\n",
            "\n",
            "   micro avg       0.83      0.83      0.83       593\n",
            "   macro avg       0.84      0.83      0.83       593\n",
            "weighted avg       0.84      0.83      0.83       593\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6-ArKGc84mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scores = model2.evaluate(ts_data, ts_ft, verbose=0)\n",
        "\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "# y_pred = model2.predict(ts_data, batch_size=64, verbose=1)\n",
        "# y_pred =(y_pred>0.5)\n",
        "\n",
        "# print(classification_report(ts_ft, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT3SqXpcraIa",
        "colab_type": "text"
      },
      "source": [
        "BiLSTM model for Past task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb1lQ0D1Gy4N",
        "colab_type": "code",
        "outputId": "136d45e3-1951-4c2d-f948-b7f40ccabc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "#Past\n",
        "\n",
        "K.clear_session()\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size,300, input_length = 145,weights = [embedding_matrix],trainable = False))\n",
        "# model.add(Embedding(vocabulary_size, 145, input_length=145))\n",
        "model.add(Bidirectional(LSTM(145, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 145, 300)          2023500   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 290)               517360    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 291       \n",
            "=================================================================\n",
            "Total params: 2,541,151\n",
            "Trainable params: 517,651\n",
            "Non-trainable params: 2,023,500\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_LvKy9DG3Km",
        "colab_type": "code",
        "outputId": "197a7782-36d5-4c5f-afd5-12ab5d5b7649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1730
        }
      },
      "source": [
        "model.fit(tr_data, tr_pt, validation_data=(val_data,val_pt), epochs=50,batch_size=128) #eposh 8 batch 128 no relu hidden"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1776 samples, validate on 592 samples\n",
            "Epoch 1/50\n",
            "1776/1776 [==============================] - 9s 5ms/step - loss: 0.6458 - acc: 0.6306 - val_loss: 0.6180 - val_acc: 0.6689\n",
            "Epoch 2/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.5435 - acc: 0.7523 - val_loss: 0.5476 - val_acc: 0.7584\n",
            "Epoch 3/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.4635 - acc: 0.8001 - val_loss: 0.4729 - val_acc: 0.8007\n",
            "Epoch 4/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.4320 - acc: 0.8198 - val_loss: 0.5085 - val_acc: 0.7905\n",
            "Epoch 5/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.4334 - acc: 0.8091 - val_loss: 0.4906 - val_acc: 0.7872\n",
            "Epoch 6/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3984 - acc: 0.8345 - val_loss: 0.4841 - val_acc: 0.7821\n",
            "Epoch 7/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3907 - acc: 0.8311 - val_loss: 0.4991 - val_acc: 0.7956\n",
            "Epoch 8/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3938 - acc: 0.8311 - val_loss: 0.4597 - val_acc: 0.8041\n",
            "Epoch 9/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3765 - acc: 0.8407 - val_loss: 0.4786 - val_acc: 0.8024\n",
            "Epoch 10/50\n",
            "1776/1776 [==============================] - 8s 5ms/step - loss: 0.3644 - acc: 0.8457 - val_loss: 0.4687 - val_acc: 0.8024\n",
            "Epoch 11/50\n",
            "1776/1776 [==============================] - 8s 4ms/step - loss: 0.3403 - acc: 0.8542 - val_loss: 0.4605 - val_acc: 0.8024\n",
            "Epoch 12/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3341 - acc: 0.8626 - val_loss: 0.4947 - val_acc: 0.7990\n",
            "Epoch 13/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3482 - acc: 0.8575 - val_loss: 0.5091 - val_acc: 0.8041\n",
            "Epoch 14/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3431 - acc: 0.8564 - val_loss: 0.4844 - val_acc: 0.7990\n",
            "Epoch 15/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3176 - acc: 0.8705 - val_loss: 0.4936 - val_acc: 0.8007\n",
            "Epoch 16/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.3022 - acc: 0.8756 - val_loss: 0.5000 - val_acc: 0.7973\n",
            "Epoch 17/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2988 - acc: 0.8761 - val_loss: 0.4785 - val_acc: 0.7939\n",
            "Epoch 18/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2777 - acc: 0.8925 - val_loss: 0.5289 - val_acc: 0.7939\n",
            "Epoch 19/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2898 - acc: 0.8829 - val_loss: 0.4882 - val_acc: 0.8007\n",
            "Epoch 20/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2683 - acc: 0.8919 - val_loss: 0.5071 - val_acc: 0.7973\n",
            "Epoch 21/50\n",
            "1776/1776 [==============================] - 8s 5ms/step - loss: 0.2545 - acc: 0.8970 - val_loss: 0.5185 - val_acc: 0.8007\n",
            "Epoch 22/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2385 - acc: 0.9093 - val_loss: 0.5079 - val_acc: 0.7922\n",
            "Epoch 23/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2333 - acc: 0.9060 - val_loss: 0.5194 - val_acc: 0.7922\n",
            "Epoch 24/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2184 - acc: 0.9172 - val_loss: 0.5366 - val_acc: 0.7922\n",
            "Epoch 25/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.2005 - acc: 0.9268 - val_loss: 0.5453 - val_acc: 0.7939\n",
            "Epoch 26/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1999 - acc: 0.9296 - val_loss: 0.6013 - val_acc: 0.8041\n",
            "Epoch 27/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1867 - acc: 0.9285 - val_loss: 0.6066 - val_acc: 0.7956\n",
            "Epoch 28/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1761 - acc: 0.9319 - val_loss: 0.5854 - val_acc: 0.8007\n",
            "Epoch 29/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1533 - acc: 0.9454 - val_loss: 0.6049 - val_acc: 0.7905\n",
            "Epoch 30/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1410 - acc: 0.9488 - val_loss: 0.6150 - val_acc: 0.7905\n",
            "Epoch 31/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.1327 - acc: 0.9538 - val_loss: 0.6583 - val_acc: 0.7922\n",
            "Epoch 32/50\n",
            "1776/1776 [==============================] - 8s 5ms/step - loss: 0.1150 - acc: 0.9589 - val_loss: 0.6790 - val_acc: 0.7939\n",
            "Epoch 33/50\n",
            "1776/1776 [==============================] - 8s 4ms/step - loss: 0.1102 - acc: 0.9611 - val_loss: 0.6620 - val_acc: 0.7821\n",
            "Epoch 34/50\n",
            "1776/1776 [==============================] - 8s 5ms/step - loss: 0.0953 - acc: 0.9668 - val_loss: 0.7187 - val_acc: 0.7956\n",
            "Epoch 35/50\n",
            "1776/1776 [==============================] - 8s 4ms/step - loss: 0.0977 - acc: 0.9679 - val_loss: 0.8260 - val_acc: 0.7905\n",
            "Epoch 36/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0830 - acc: 0.9730 - val_loss: 0.7256 - val_acc: 0.7787\n",
            "Epoch 37/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0811 - acc: 0.9724 - val_loss: 0.7155 - val_acc: 0.7804\n",
            "Epoch 38/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0755 - acc: 0.9825 - val_loss: 0.7635 - val_acc: 0.7821\n",
            "Epoch 39/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0636 - acc: 0.9786 - val_loss: 0.7901 - val_acc: 0.7922\n",
            "Epoch 40/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0550 - acc: 0.9809 - val_loss: 0.8415 - val_acc: 0.8007\n",
            "Epoch 41/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0650 - acc: 0.9769 - val_loss: 0.8608 - val_acc: 0.7804\n",
            "Epoch 42/50\n",
            "1776/1776 [==============================] - 8s 4ms/step - loss: 0.0636 - acc: 0.9837 - val_loss: 0.7792 - val_acc: 0.7804\n",
            "Epoch 43/50\n",
            "1776/1776 [==============================] - 8s 4ms/step - loss: 0.0619 - acc: 0.9786 - val_loss: 0.8486 - val_acc: 0.8007\n",
            "Epoch 44/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0554 - acc: 0.9865 - val_loss: 0.7945 - val_acc: 0.7804\n",
            "Epoch 45/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0533 - acc: 0.9842 - val_loss: 0.8285 - val_acc: 0.7922\n",
            "Epoch 46/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0413 - acc: 0.9904 - val_loss: 0.8757 - val_acc: 0.7990\n",
            "Epoch 47/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0430 - acc: 0.9899 - val_loss: 0.8528 - val_acc: 0.7787\n",
            "Epoch 48/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0365 - acc: 0.9904 - val_loss: 0.9582 - val_acc: 0.7905\n",
            "Epoch 49/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0369 - acc: 0.9887 - val_loss: 0.9550 - val_acc: 0.7973\n",
            "Epoch 50/50\n",
            "1776/1776 [==============================] - 7s 4ms/step - loss: 0.0305 - acc: 0.9938 - val_loss: 0.9261 - val_acc: 0.7821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa387c10630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-5WsgytZtx",
        "colab_type": "text"
      },
      "source": [
        "Stacked BiLSTM for Past task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEvFT3ffs_BU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Past LSTM2\n",
        "K.clear_session()\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(vocabulary_size,300, input_length = 145,weights = [embedding_matrix],trainable = False))\n",
        "# model.add(Embedding(vocabulary_size, 145, input_length=145))\n",
        "model2.add(Bidirectional(LSTM(145, dropout=0.2, recurrent_dropout=0.2,return_sequences=True)))\n",
        "model2.add(Bidirectional(LSTM(145, dropout=0.1, recurrent_dropout=0.1)))\n",
        "model2.add(Dense(64,activation = 'relu'))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "adg= optimizers.Adagrad(lr=0.01)\n",
        "model2.compile(loss='binary_crossentropy', optimizer=adg, metrics=['accuracy'])\n",
        "# model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRFhkekKtEWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.fit(tr_data, tr_pt, validation_data=(val_data,val_pt), epochs=50,batch_size=128) #eposh 8 batch 128 no relu hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUkfWfaoso_3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAS0PMF6tuUt",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the test data for future task "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEYgaCrPtjdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "scores = model.evaluate(ts_data, ts_pt, verbose=0)\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1XpIdlStxPo",
        "colab_type": "text"
      },
      "source": [
        "Generating a classification report for the test data for future task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RAmOxrbtrIh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(ts_data, batch_size=64, verbose=1)\n",
        "y_pred =(y_pred>0.5)\n",
        "\n",
        "print(classification_report(ts_ft, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1XMAjVrxuSqV",
        "colab": {}
      },
      "source": [
        "# scores = model2.evaluate(ts_data, ts_pt, verbose=0)\n",
        "\n",
        "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "# y_pred = model2.predict(ts_data, batch_size=64, verbose=1)\n",
        "# y_pred =(y_pred>0.5)\n",
        "\n",
        "# print(classification_report(ts_pt, y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}